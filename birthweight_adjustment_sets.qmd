---
title: "Birthweight Application"
format: pdf
editor: visual
---

```{r}
library(tidyverse)
library(truncdist)
library(nnet)
library(car)
library(randomForest) 
library(tidybayes)
library(bayesplot)
library(gsynth)
library(colorspace)
library(ggbeeswarm)
source("utilities.R")
```

```{r}
# saveRDS(merged_bw_df_selected, file = "birthweight_data_preprocess.rds")
merged_bw_df_selected <- readRDS("birthweight_data_preprocess.rds")
raw_names <- colnames(merged_bw_df_selected)[11:35]
colnames(merged_bw_df_selected)[11:35] <- paste0("x", 1:25)
```

DML random forest.

```{r}
x <- merged_bw_df_selected[, c(2,4:5,7,11:35)]
d <- merged_bw_df_selected[,]$pm25
y <- merged_bw_df_selected[,]$bw_mean

set.seed(202505)

#DML with Random Forest:
dreg <- function(x,d){randomForest(x, d)} 
yreg <- function(x,y){randomForest(x, y)} 

```

```{r}
run_analysis <- function(data,
                         adj_cols = character(0L),   # adjustment set X
                         d_col     = "pm25",          # treatment   column
                         y_col     = "bw_mean",       # outcome     column
                         unit_col  = "unit",          # ID for interFE
                         time_col  = "time",          # ID for interFE
                         T_periods = 7L,              # # of time points
                         M_factors = 3L,              # # of latent factors in Stan
                         nfold     = 5L,
                         vb_draws  = 2000L,
                         seed      = 123) {

  ## 1.1 Split variables -------------------------------------------
  X <- if (length(adj_cols)) data[, adj_cols, drop = FALSE] else NULL
  d <- data[[d_col]]
  y <- data[[y_col]]

  ## 1.2 DML --------------------------------------------------------
  set.seed(seed)
  dml_fit <- dml_plm(X, d, y, dreg, yreg, nfold = nfold)

  coef_hat <- as.numeric(dml_fit$coef.est)
  se_hat   <- as.numeric(dml_fit$se)
  ci_95    <- coef_hat + c(-1.96, 1.96) * se_hat

  ## 1.3  Residuals to matrices -------------------------------------
  resD_mat <- matrix(dml_fit$resD, ncol = T_periods, byrow = TRUE)
  resY_mat <- matrix(dml_fit$resY, ncol = T_periods, byrow = TRUE)

  ## 1.4  Stan (Factor model VB) ------------------------------------
  N_units <- nrow(resD_mat)
  stan_data <- list(
    K = T_periods, Q = T_periods, N = N_units,
    M = M_factors, d = resD_mat,  y = resY_mat
  )
  sm_factor <- cmdstanr::cmdstan_model("stan/time_nc_factor.stan")
  vb_fit <- sm_factor$variational(data = stan_data, seed = seed, draws = vb_draws)
  vb_sum <- posterior::summarise_draws(
              vb_fit$draws("beta"),
              mean,
              ~quantile(.x, probs = c(0.025, 0.975))
            )

  ## 1.5  interFE ---------------------------------------------------
  df_fe <- data.frame(
            unit = rep(1:N_units, each = T_periods), # unit
            time = rep(1:T_periods, N_units),
            Y    = dml_fit$resY,
            D    = dml_fit$resD
          )
  # flip time and unit does not change much
  fe_fit <- interFE(Y ~ D, data = df_fe,
                    index = c("unit", "time"),
                    r     = M_factors,
                    force = "none",
                    nboots = 100)

  ## 1.6  Return --------------------------------------------
  list(
    adj_set     = adj_cols,
    dml_coef    = coef_hat,
    dml_ci_95   = ci_95,
    vb_summary  = vb_sum,
    interFE_est = fe_fit$beta
  )
}
```

```{r}

# Set up parallel processing
cov_list <- list(income=7, age = 11:19, race = 20:26, educ=27:30, foreign = 31, care = 32:35)

# Create a list of all tasks to run in parallel
all_tasks <- list()
task_id <- 1

for(i in 6:0) {
  combinations <- combn(6, i)
  for(j in 1:ncol(combinations)) {
    indices <- unlist(cov_list[combinations[, j]])
    adj_cols <- colnames(merged_bw_df_selected)[c(2, 4:5, indices)]
    
    # Store each task as a list
    all_tasks[[task_id]] <- list(
      i = i,
      j = j,
      adj_cols = adj_cols
    )
    task_id <- task_id + 1
  }
}

cat("Total tasks to run:", length(all_tasks), "\n")

# Define a function to run a single task
run_single_task <- function(task) {
  result <- run_analysis(merged_bw_df_selected, adj_cols = task$adj_cols)
  return(list(
    i = task$i,
    j = task$j,
    result = result
  ))
}

# Run all tasks in parallel
cat("Starting parallel processing...\n")
start_time <- Sys.time()

library(future)
library(future.apply)

# Set up parallel backend
plan(multicore, workers = 32)

# Run in parallel
all_results <- future_lapply(
  all_tasks,
  run_single_task,
  future.seed = TRUE
)

end_time <- Sys.time()
cat("Parallel processing completed in:", round(difftime(end_time, start_time, units = "mins"), 2), "minutes\n")

# Reorganize results back into the original nested structure
results_list <- list()
for(i in 6:0) {
  results_list[[as.character(i)]] <- list()
}

for(task_result in all_results) {
  i <- task_result$i
  j <- task_result$j
  results_list[[as.character(i)]][[j]] <- task_result$result
}

# Save results
saveRDS(results_list, file = "results_list3.RDS")
cat("Results saved to results_list.RDS\n")
```

```{r}
# Extract results from results_list
results_list <- readRDS("results_list3.RDS")

# Create a function to extract estimates from each result
extract_estimates <- function(result) {
  list(
    dml_coef = result$dml_coef,
    factor_conf = result$vb_summary$mean,
    interFE_est = result$interFE_est
  )
}

combination_names <- c(
  "All 6 covariates",
  "Any 5 covariates", 
  "Any 4 covariates",
  "Any 3 covariates", 
  "Any 2 covariates",
  "Any 1 covariate",
  "No covariates"
)

# Extract all estimates
plot_data <- tibble()

for(i in 6:0) {
  len <- length(results_list[[as.character(i)]])
  if(len > 0) {
    # For each combination at level i
    estimates_i <- map(results_list[[as.character(i)]], extract_estimates)
    
    # Calculate mean estimates across all combinations at this level
    mean_dml <- map_dbl(estimates_i, "dml_coef")
    mean_factor <- map_dbl(estimates_i, "factor_conf")
    mean_interFE <- map_dbl(estimates_i, "interFE_est")
    
    # Add to plot data
    plot_data <- bind_rows(
      plot_data,
      tibble(
        setting = combination_names[7-i],
        model = rep(c("DML (NUC)", "IFE", "Factor Confounding"), each = len),
        estimate = c(mean_dml, mean_interFE, mean_factor) * 10, # Convert to per 10 µg/m³
      )
    )
  }
}

# Set factor levels to preserve order
plot_data$setting <- factor(plot_data$setting, levels = combination_names)
plot_data$model <- factor(plot_data$model, levels = c("DML (NUC)", "IFE", "Factor Confounding"))

plot_data |> group_by(setting, model) |>
  summarise(mean = mean(estimate), sd = sd(estimate), .groups = "drop") |>
  filter(!is.na(sd)) |>
  arrange(setting, sd) |>
  ggplot() + geom_col(aes(x = setting, y = sd, fill = model), position="dodge") + theme_bw(base_size = 16) + ylab("Standard Deviation of Estimates") + 
  xlab("Covariates Included") + 
  labs(fill = "Model") +
  # scale_fill_manual(values = c("DML (NUC)" = "#0072B2",
  #                                "Factor Confounding" = "firebrick",
  #                                "IFE" = "#009E73")) 
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()) ->
        p_sd

p_sd


plot_data |> group_by(setting, model) |>
  summarise(rmse = sqrt(mean((estimate + 16)^2)), sd = sd(estimate), .groups = "drop") |>
  filter(!is.na(rmse)) |>
  arrange(setting, rmse) |>
  ggplot() + geom_col(aes(x = setting, y = rmse, fill = model), position="dodge") + theme_bw(base_size = 16) + ylab("Root mean squared difference\nfrom -16g per 10 µg/m³") + 
  xlab("Covariates Included") + 
  labs(fill = "Model") +
  # scale_fill_manual(values = c("DML (NUC)" = "#0072B2",
  #                                "Factor Confounding" = "firebrick",
  #                                "IFE" = "#009E73")) 
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()) ->
        p_rmse

p_rmse

ggsave("sensitivity_rmse.png", width=6, height=6)

plot_data |> group_by(setting, model) |>
  summarise(median = median(estimate), sd = sd(estimate), .groups = "drop") |>
  arrange(setting, sd) |>
  ggplot() + geom_col(aes(x = setting, y = median, fill = model), position="dodge") + theme_bw(base_size = 16) + 
  # scale_fill_manual(values = c("DML (NUC)" = "#0072B2",
  #                                "Factor Confounding" = "firebrick",
  #                                "IFE" = "#009E73")) +
  scale_fill_discrete_qualitative(palette = "Dark 3") +
  ylab("Median of Estimates") + 
  xlab("Covariates Included") + 
  labs(fill = "Model") +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()) ->
        p_median
p_median
ggsave("sensitivity_median.png", width=6, height=6)
# Create the plot
p_combinations <- ggplot(plot_data,
       aes(x = setting,
           y = estimate,
           colour = model)) +
  geom_point(position = position_dodge(width = .35),
             size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Estimates by Number of Covariate Included",
       x = "Covariates Included",
       y = "Birthweight change (g)\nper 10 µg/m³ PM2.5 increase",
       colour = "Model") +
  # scale_colour_manual(values = c("DML (NUC)" = "#0072B2",
  #                                "Factor Confounding" = "firebrick",
  #                                "IFE" = "#009E73")) +
  scale_colour_discrete_qualitative(palette = "Dark 3") +
  theme_bw(base_size = 16) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank())

p_combinations


# Create the beehive plot
p_beehive <- ggplot(plot_data,
       aes(x = setting,
           y = estimate,
           colour = model)) +
  geom_beeswarm(size = 2, 
                dodge.width = 0.7,
                alpha = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey50") +
  # stat_summary(aes(group = model),
  #              fun = mean,
  #              geom = "point",
  #              size = 3,
  #              shape = 18,  # diamond shape for means
  #              position = position_dodge(width = 0.7)) +
  labs(title = "Sensitivity to Included Covariates",
       x = "Covariates Included",
       y = "Birthweight change (g)\nper 10 µg/m³ PM2.5 increase",
       colour = "Model") +
  # scale_colour_manual(values = c("DML (NUC)" = "#0072B2",
  #                                "Factor Confounding" = "firebrick",
  #                                "IFE" = "#009E73")) +
  scale_colour_discrete_qualitative(palette = "Dark 3") +
  theme_bw(base_size = 16) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank())

p_beehive

ggsave("beehive.png", width=6, height=6)

library(patchwork)
p_beehive + (p_median / p_sd) + 
  plot_annotation(title = "Sensitivity to Included Covariates",
                  subtitle = "Beeswarm plot with median and standard deviation of estimates") &
  theme(plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 16))
```

```{r}
results_raw <- run_analysis(merged_bw_df_selected)
results_T <- run_analysis(merged_bw_df_selected, adj_cols = colnames(merged_bw_df_selected)[c(2,7)])
results_S <- run_analysis(merged_bw_df_selected, adj_cols = colnames(merged_bw_df_selected)[4:5], seed = 111)
results_X <- run_analysis(merged_bw_df_selected, adj_cols = colnames(merged_bw_df_selected)[11:35])
results_ST <- run_analysis(merged_bw_df_selected, 
                           adj_cols = colnames(merged_bw_df_selected)[c(2,4:5,7)])
results_XT <- run_analysis(merged_bw_df_selected, 
                           adj_cols = colnames(merged_bw_df_selected)[c(2,7,11:35)])
results_XS <- run_analysis(merged_bw_df_selected, 
                           adj_cols = colnames(merged_bw_df_selected)[c(4:5,11:35)])
results_all <- run_analysis(merged_bw_df_selected, 
                            adj_cols= colnames(merged_bw_df_selected)[c(2,4:5,7,11:35)])
```

plot the estimate of omitting some covariates:

```{r}
omit_df <- tribble(
  ~setting,                       ~model,               ~estimate, ~lwr, ~upr,
  "No Adjustment",                "DML (NUC)",          -47.72,   -53.32, -42.12,
  "No Adjustment",                "IFE",                -8.78,    -35.17,  15.99,
  "No Adjustment",                "Factor Confounding", -9.284,   -13.7,   -4.67, 
  "Spatial Only",                 "DML (NUC)",           4.34,    -3.36,   12.04,
  "Spatial Only",                 "IFE",                 -15.30,  -37.87,  7.274,
  "Spatial Only",                 "Factor Confounding", -8.498,   -15.16, -1.488,  
  "Time-Varying Only",            "DML (NUC)",          -56.76,   -62.86, -50.659,
  "Time-Varying Only",            "IFE",                 1.273,   -19.28, 15.51, 
  "Time-Varying Only",            "Factor Confounding", -12.624,  -18.3, -6.7,
  "Static Only",                  "DML (NUC)",          -7.4,     -13.356, -1.443,
  "Static Only",                  "IFE",                -7.531,   -30.38, 8.883,
  "Static Only",                  "Factor Confounding", -10.20,   -15.567, -4.553,
  "Time-Varying + Spatial",       "DML (NUC)",          -24.45,   -36.01, -12.89,
  "Time-Varying + Spatial",       "IFE",                -7.92,    -35.9,   21.94,
  "Time-Varying + Spatial",       "Factor Confounding", -18.88,   -30.68, -6.32,
  "Time-Varying + Spatial",       "Double NC",         -37.666,   -87.32, 1.199,
  "Spatial + Static",             "DML (NUC)",          -3.44,    -10.96,  4.083,
  "Spatial + Static",             "IFE",                -19.97,   -31.75,  9.74,
  "Spatial + Static",             "Factor Confounding", -8.75,    -15.6,  -1.52,
  "Spatial + Static",             "Double NC",         -25.10,    -65.71,  15.514,
  "Time-Varying + Static",        "DML (NUC)",          -12.08,  -18.85,   -5.3,
  "Time-Varying + Static",        "IFE",                -6.20,   -28.62,    8.57,
  "Time-Varying + Static",        "Factor Confounding", -14.78,   -21.1, -8.08,
  "All Confounders",              "DML (NUC)",          -11.98,   -21.96, -1.995,
  "All Confounders",              "IFE",                -7.5,     -40.81, 16.35,
  "All Confounders",              "Factor Confounding", -15.94,   -25.08, -6.33,
  "All Confounders",              "Double NC",         -18.39,   -54.41, 17.62
)

# Preserve the logical order on the x‑axis
omit_df$setting <- factor(omit_df$setting,
  levels = c(
    "No Adjustment",
    "Spatial Only",
    "Time-Varying Only",
    "Static Only",
    "Time-Varying + Spatial",
    "Spatial + Static",
    "Time-Varying + Static",
    "All Confounders")
)
omit_df$model <- factor(omit_df$model, levels = c("DML (NUC)", "IFE", "Factor Confounding", "Double NC"))

# Plot: point estimate + 95% CI, one colour per model
p_omit <- ggplot(omit_df,
       aes(x = setting,
           y = estimate,
           colour = model #,shape  = model
           )) +
  geom_point(position = position_dodge(width = .35),
             size = 2) +
  geom_errorbar(aes(ymin = lwr, ymax = upr),
                width = .15,
                position = position_dodge(width = .35),
                linewidth = .8) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Estimates Under Different Confounder Adjustments",
       x = NULL,
       y = "Birthweight change (g)\nper 10 µg/m³ PM2.5 increase",
       colour = "Model", shape = NULL) +
  scale_colour_manual(values = c("DML (NUC)" = "#0072B2",
                                 "Factor Confounding" = "firebrick",
                                 "IFE" = "#009E73",
                                 "Double NC" = "#D55E00")) +
  # scale_shape_manual(values = c("DML naïve"          = 16,   # filled circle
  #                               "Factor confounding" = 17)) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 30, hjust = 0.9),
        panel.grid.minor = element_blank()
        )
p_omit
# ggsave("bw_vary_adjustments_1.pdf", p_omit, width = 6.5, height = 5, units = "in", dpi = 300)
```

## Double negative control

```{r}
library(fixest)
library(gmm)
```

Use outcome in previous year and exposure in next year as negative controls.

```{r}
bw_panel <- merged_bw_df_selected %>% 
  arrange(zip, year) %>%     # make time increasing within ZIP
  group_by(zip) %>% 
  mutate(
    ## negative controls
    bw_lag1     = lag(bw_mean, 1),   #  W_i   = Y_{i-1}
    pm25_lead1  = lead(pm25, 1),     #  Z_i   = X_{i+1}
    # ln_income   = log(median_income + 1),   # scale-robust
    year_fe     = factor(year)              # year as factor
  ) %>% 
  ungroup() %>% 
  drop_na(bw_lag1, pm25_lead1)        # first & last year of each ZIP lose 1 row
```

```{r}
rhs   <- paste(c("pm25", covars), collapse = " + ")
fml   <- as.formula(
  paste0("bw_mean ~ ", rhs, " | zip + year_fe")
)

ols_fe <- feols(fml, data = bw_panel, se = "cluster")
# ols_fe <- feols(
#   bw_mean ~ pm25 + median_income + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 | zip + year_fe,
#   data = bw_panel,
#   se = "cluster"
# )
# etable(ols_fe, se.below = TRUE)
coeftable(ols_fe)[c("pm25"), ]
```

```{r}
nc_test <- feols(
  bw_lag1 ~ pm25 + pm25_lead1 + median_income + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 + x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 + x21 + x22 + x23 + x24 + x25 | zip + year_fe,
  data = bw_panel,
  se   = "cluster"
)
coeftable(nc_test)[c("pm25","pm25_lead1"), ]
```

```{r}
# remove location and time fixed effect
bw_panel_w <- bw_panel %>% 
  group_by(zip) %>% 
  mutate(across(c(bw_mean, pm25, bw_lag1, pm25_lead1, median_income, x1:x25), 
                ~ .x - mean(.x, na.rm = TRUE))) %>%
  ungroup() %>% 
  group_by(year_fe) %>%     
  mutate(across(c(bw_mean, pm25, bw_lag1, pm25_lead1, median_income, x1:x25), 
                ~ .x - mean(.x, na.rm = TRUE))) %>%
  ungroup()

covars <- c("median_income")  #, paste0("x", 1:25)

make_mom <- function(theta, d) {
  kV      <- length(covars)          # 25 in your data
  beta1   <- theta[kV + 3]           # last element of theta

  ## theta layout:
  ##   [1]     γ0
  ##   [2]     γ2  (coefficient on W)
  ##   [3:(kV+2)] γ_V (25 covariate terms)
  ##   [kV+3] β1  (== γ1, coefficient on X)

  gamma_vec <- c(
    theta[1],        # γ0
    beta1,           # γ1  (== β1)
    theta[2:(kV+2)]  # γ2 and γ_V
  )

  X  <- d$pm25
  W  <- d$bw_lag1
  V  <- as.matrix(d[, covars])
  Z  <- d$pm25_lead1
  Y <- d$bw_mean

  Bmat <- cbind(1, X, W, V)          # n × (kV+3)
  Qmat <- cbind(1, X, Z, V)          # n × (kV+3)

  resid <- Y - drop(Bmat %*% gamma_vec) # n-vector
  m <- resid * Qmat 
  m                        # n × (3+kV)
}

theta0 <- rep(0, 2 + length(covars) + 1)   # γ0 γ2 γ_V … β1
names(theta0) <- c(
  "gamma0",
  "gamma2",
  paste0("gamma_", covars),
  "beta1"
)
gmm_fit <- gmm(
  g        = make_mom,
  x        = bw_panel, # bw_panel_w
  t0       = theta0,
  type     = "twoStep",
  vcov     = "HAC",      # now safe: every column has variance
  prewhite = FALSE
)

beta_tab <- summary(gmm_fit)$coefficients["beta1", ]
beta_tab
beta_hat <- beta_tab["Estimate"]
se_hat   <- beta_tab["Std. Error"]
ci_95    <- beta_hat + qnorm(c(.025, .975)) * se_hat
ci_95
```